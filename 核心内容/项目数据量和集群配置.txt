关于系统中数据量  和   集群配置，运行时长的估算：




1、数据量：
活跃用户100万级别（唯品会、一号店、58同城、美团）
每天产生点击流日志量  40g   2k一条日志   ？？条
还要加上合作伙伴的流量日志 、业务数据（用户信息、订单库、产品信息）
最后，算下来，约100G


2、集群配置

假如数据统计需求中时间跨度最长为6个月
那么，6个月的数据量= 6*30*100G=20T


假如HDFS集群的机器（PC服务器）配置如下：
cpu ：
2个   2core 8 thread  2.5GHZ  
内存：64G
硬盘：scsi接口硬盘 1T* 4块（或者8块）


从存储容量来规划:
规划HDFS集群的规模（25个节点）：
namenode  2个
datanode  20T*3个副本  /  3T  =  20-25台  （但是还要考虑 处理之后的结果数据，还要考虑冗余，选35台比较合适）
zookeeper + journalnode 3台  

从运算负载来规划：

考虑因素1、job数：
    运算的业务模型，以友盟为例，通用的流量分析，指标模型就有约100个（有固定的统计需求，也有临时统计需求）
	每个指标（sql程序）平均被hive翻译为4个job
	总共的job数== 100 * 4 =400 job
	
考虑因素2、数据量
	100G 数据被切片后  = 100G  /128m = 	800切片
	根据上步骤所得的400job ，结合数据量800切片，可得出maptask的数量： 
	    400*800 maptask = 320000 maptask
		<！400*（每台机器上的cpu线程数20）= 8000 reducetask！>
		如果集群中运算节点为25台，每台2cpu  20线程，意味着，集群可同时运行 500个maptask
		一个maptask平均运行时长约0.5分钟
		在这样的集群规模下，320000 maptask需要运行的时长：
		    320000/500= 640 * 0.5 =320分钟 /60  = 5小时
		《如果同时提交的任务数超过集群的slot总数量，yarn会对提交的任务进行调度--fifo、Capacity、fair》